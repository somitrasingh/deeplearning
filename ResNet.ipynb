{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somitrasingh/deeplearning/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2rhg-1K_SwW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWkcwME-_whA"
      },
      "outputs": [],
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
        "    super(block, self).__init__()\n",
        "\n",
        "    self.expansion = 4\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(intermediate_channels, intermediate_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(intermediate_channels*self.expansion)\n",
        "\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.identity_downsample = identity_downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x.clone()\n",
        "    x = self.relu(self.bn1(self.conv1(x)))\n",
        "    x = self.relu(self.bn2(self.conv2(x)))\n",
        "    x = self.bn3(self.conv3(x))\n",
        "\n",
        "    if self.identity_downsample is not None:\n",
        "      identity = self.identity_downsample(identity)\n",
        "\n",
        "    x += identity\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vVkgBEiEpab"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, img_channels, num_classes):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Conv2d(img_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.layer1 = self._make_layer(block, layers[0], 64, stride=1)\n",
        "    self.layer2 = self._make_layer(block, layers[1], 128, stride=2)\n",
        "    self.layer3 = self._make_layer(block, layers[2], 256, stride=2)\n",
        "    self.layer4 = self._make_layer(block, layers[3], 512, stride=2)\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _make_layer(self, block, layer, intermediate_channels, stride):\n",
        "    layers = []\n",
        "\n",
        "    identity_downsample = None\n",
        "    if stride != 1 or self.in_channels != intermediate_channels*4:\n",
        "      identity_downsample = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channels, intermediate_channels*4, kernel_size=1, stride=stride),\n",
        "          nn.BatchNorm2d(intermediate_channels*4))\n",
        "\n",
        "    layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride=stride))\n",
        "\n",
        "    self.in_channels = intermediate_channels*4\n",
        "\n",
        "    for i in range(layer-1):\n",
        "      layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWScIeBYdFBI",
        "outputId": "2059daee-21c8-4256-d984-897a1565b824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.CenterCrop(112),\n",
        "    transforms.Lambda(lambda image: image.convert(\"RGB\")),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.Caltech101(root='./data', download=True, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=500, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGkEDFwldmJ1",
        "outputId": "16142946-0dda-4ddb-fc2a-8a9d56d6375e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 114, 114]           9,472\n",
            "       BatchNorm2d-2         [-1, 64, 114, 114]             128\n",
            "              ReLU-3         [-1, 64, 114, 114]               0\n",
            "         MaxPool2d-4           [-1, 64, 57, 57]               0\n",
            "            Conv2d-5           [-1, 64, 57, 57]           4,160\n",
            "       BatchNorm2d-6           [-1, 64, 57, 57]             128\n",
            "              ReLU-7           [-1, 64, 57, 57]               0\n",
            "            Conv2d-8           [-1, 64, 57, 57]          36,928\n",
            "       BatchNorm2d-9           [-1, 64, 57, 57]             128\n",
            "             ReLU-10           [-1, 64, 57, 57]               0\n",
            "           Conv2d-11          [-1, 256, 57, 57]          16,640\n",
            "      BatchNorm2d-12          [-1, 256, 57, 57]             512\n",
            "           Conv2d-13          [-1, 256, 57, 57]          16,640\n",
            "      BatchNorm2d-14          [-1, 256, 57, 57]             512\n",
            "             ReLU-15          [-1, 256, 57, 57]               0\n",
            "            block-16          [-1, 256, 57, 57]               0\n",
            "           Conv2d-17           [-1, 64, 57, 57]          16,448\n",
            "      BatchNorm2d-18           [-1, 64, 57, 57]             128\n",
            "             ReLU-19           [-1, 64, 57, 57]               0\n",
            "           Conv2d-20           [-1, 64, 57, 57]          36,928\n",
            "      BatchNorm2d-21           [-1, 64, 57, 57]             128\n",
            "             ReLU-22           [-1, 64, 57, 57]               0\n",
            "           Conv2d-23          [-1, 256, 57, 57]          16,640\n",
            "      BatchNorm2d-24          [-1, 256, 57, 57]             512\n",
            "             ReLU-25          [-1, 256, 57, 57]               0\n",
            "            block-26          [-1, 256, 57, 57]               0\n",
            "           Conv2d-27           [-1, 64, 57, 57]          16,448\n",
            "      BatchNorm2d-28           [-1, 64, 57, 57]             128\n",
            "             ReLU-29           [-1, 64, 57, 57]               0\n",
            "           Conv2d-30           [-1, 64, 57, 57]          36,928\n",
            "      BatchNorm2d-31           [-1, 64, 57, 57]             128\n",
            "             ReLU-32           [-1, 64, 57, 57]               0\n",
            "           Conv2d-33          [-1, 256, 57, 57]          16,640\n",
            "      BatchNorm2d-34          [-1, 256, 57, 57]             512\n",
            "             ReLU-35          [-1, 256, 57, 57]               0\n",
            "            block-36          [-1, 256, 57, 57]               0\n",
            "           Conv2d-37          [-1, 128, 57, 57]          32,896\n",
            "      BatchNorm2d-38          [-1, 128, 57, 57]             256\n",
            "             ReLU-39          [-1, 128, 57, 57]               0\n",
            "           Conv2d-40          [-1, 128, 29, 29]         147,584\n",
            "      BatchNorm2d-41          [-1, 128, 29, 29]             256\n",
            "             ReLU-42          [-1, 128, 29, 29]               0\n",
            "           Conv2d-43          [-1, 512, 29, 29]          66,048\n",
            "      BatchNorm2d-44          [-1, 512, 29, 29]           1,024\n",
            "           Conv2d-45          [-1, 512, 29, 29]         131,584\n",
            "      BatchNorm2d-46          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-47          [-1, 512, 29, 29]               0\n",
            "            block-48          [-1, 512, 29, 29]               0\n",
            "           Conv2d-49          [-1, 128, 29, 29]          65,664\n",
            "      BatchNorm2d-50          [-1, 128, 29, 29]             256\n",
            "             ReLU-51          [-1, 128, 29, 29]               0\n",
            "           Conv2d-52          [-1, 128, 29, 29]         147,584\n",
            "      BatchNorm2d-53          [-1, 128, 29, 29]             256\n",
            "             ReLU-54          [-1, 128, 29, 29]               0\n",
            "           Conv2d-55          [-1, 512, 29, 29]          66,048\n",
            "      BatchNorm2d-56          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-57          [-1, 512, 29, 29]               0\n",
            "            block-58          [-1, 512, 29, 29]               0\n",
            "           Conv2d-59          [-1, 128, 29, 29]          65,664\n",
            "      BatchNorm2d-60          [-1, 128, 29, 29]             256\n",
            "             ReLU-61          [-1, 128, 29, 29]               0\n",
            "           Conv2d-62          [-1, 128, 29, 29]         147,584\n",
            "      BatchNorm2d-63          [-1, 128, 29, 29]             256\n",
            "             ReLU-64          [-1, 128, 29, 29]               0\n",
            "           Conv2d-65          [-1, 512, 29, 29]          66,048\n",
            "      BatchNorm2d-66          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-67          [-1, 512, 29, 29]               0\n",
            "            block-68          [-1, 512, 29, 29]               0\n",
            "           Conv2d-69          [-1, 128, 29, 29]          65,664\n",
            "      BatchNorm2d-70          [-1, 128, 29, 29]             256\n",
            "             ReLU-71          [-1, 128, 29, 29]               0\n",
            "           Conv2d-72          [-1, 128, 29, 29]         147,584\n",
            "      BatchNorm2d-73          [-1, 128, 29, 29]             256\n",
            "             ReLU-74          [-1, 128, 29, 29]               0\n",
            "           Conv2d-75          [-1, 512, 29, 29]          66,048\n",
            "      BatchNorm2d-76          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-77          [-1, 512, 29, 29]               0\n",
            "            block-78          [-1, 512, 29, 29]               0\n",
            "           Conv2d-79          [-1, 256, 29, 29]         131,328\n",
            "      BatchNorm2d-80          [-1, 256, 29, 29]             512\n",
            "             ReLU-81          [-1, 256, 29, 29]               0\n",
            "           Conv2d-82          [-1, 256, 15, 15]         590,080\n",
            "      BatchNorm2d-83          [-1, 256, 15, 15]             512\n",
            "             ReLU-84          [-1, 256, 15, 15]               0\n",
            "           Conv2d-85         [-1, 1024, 15, 15]         263,168\n",
            "      BatchNorm2d-86         [-1, 1024, 15, 15]           2,048\n",
            "           Conv2d-87         [-1, 1024, 15, 15]         525,312\n",
            "      BatchNorm2d-88         [-1, 1024, 15, 15]           2,048\n",
            "             ReLU-89         [-1, 1024, 15, 15]               0\n",
            "            block-90         [-1, 1024, 15, 15]               0\n",
            "           Conv2d-91          [-1, 256, 15, 15]         262,400\n",
            "      BatchNorm2d-92          [-1, 256, 15, 15]             512\n",
            "             ReLU-93          [-1, 256, 15, 15]               0\n",
            "           Conv2d-94          [-1, 256, 15, 15]         590,080\n",
            "      BatchNorm2d-95          [-1, 256, 15, 15]             512\n",
            "             ReLU-96          [-1, 256, 15, 15]               0\n",
            "           Conv2d-97         [-1, 1024, 15, 15]         263,168\n",
            "      BatchNorm2d-98         [-1, 1024, 15, 15]           2,048\n",
            "             ReLU-99         [-1, 1024, 15, 15]               0\n",
            "           block-100         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-101          [-1, 256, 15, 15]         262,400\n",
            "     BatchNorm2d-102          [-1, 256, 15, 15]             512\n",
            "            ReLU-103          [-1, 256, 15, 15]               0\n",
            "          Conv2d-104          [-1, 256, 15, 15]         590,080\n",
            "     BatchNorm2d-105          [-1, 256, 15, 15]             512\n",
            "            ReLU-106          [-1, 256, 15, 15]               0\n",
            "          Conv2d-107         [-1, 1024, 15, 15]         263,168\n",
            "     BatchNorm2d-108         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-109         [-1, 1024, 15, 15]               0\n",
            "           block-110         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-111          [-1, 256, 15, 15]         262,400\n",
            "     BatchNorm2d-112          [-1, 256, 15, 15]             512\n",
            "            ReLU-113          [-1, 256, 15, 15]               0\n",
            "          Conv2d-114          [-1, 256, 15, 15]         590,080\n",
            "     BatchNorm2d-115          [-1, 256, 15, 15]             512\n",
            "            ReLU-116          [-1, 256, 15, 15]               0\n",
            "          Conv2d-117         [-1, 1024, 15, 15]         263,168\n",
            "     BatchNorm2d-118         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-119         [-1, 1024, 15, 15]               0\n",
            "           block-120         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-121          [-1, 256, 15, 15]         262,400\n",
            "     BatchNorm2d-122          [-1, 256, 15, 15]             512\n",
            "            ReLU-123          [-1, 256, 15, 15]               0\n",
            "          Conv2d-124          [-1, 256, 15, 15]         590,080\n",
            "     BatchNorm2d-125          [-1, 256, 15, 15]             512\n",
            "            ReLU-126          [-1, 256, 15, 15]               0\n",
            "          Conv2d-127         [-1, 1024, 15, 15]         263,168\n",
            "     BatchNorm2d-128         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-129         [-1, 1024, 15, 15]               0\n",
            "           block-130         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-131          [-1, 256, 15, 15]         262,400\n",
            "     BatchNorm2d-132          [-1, 256, 15, 15]             512\n",
            "            ReLU-133          [-1, 256, 15, 15]               0\n",
            "          Conv2d-134          [-1, 256, 15, 15]         590,080\n",
            "     BatchNorm2d-135          [-1, 256, 15, 15]             512\n",
            "            ReLU-136          [-1, 256, 15, 15]               0\n",
            "          Conv2d-137         [-1, 1024, 15, 15]         263,168\n",
            "     BatchNorm2d-138         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-139         [-1, 1024, 15, 15]               0\n",
            "           block-140         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-141          [-1, 512, 15, 15]         524,800\n",
            "     BatchNorm2d-142          [-1, 512, 15, 15]           1,024\n",
            "            ReLU-143          [-1, 512, 15, 15]               0\n",
            "          Conv2d-144            [-1, 512, 8, 8]       2,359,808\n",
            "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-146            [-1, 512, 8, 8]               0\n",
            "          Conv2d-147           [-1, 2048, 8, 8]       1,050,624\n",
            "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-149           [-1, 2048, 8, 8]       2,099,200\n",
            "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-151           [-1, 2048, 8, 8]               0\n",
            "           block-152           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-153            [-1, 512, 8, 8]       1,049,088\n",
            "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-155            [-1, 512, 8, 8]               0\n",
            "          Conv2d-156            [-1, 512, 8, 8]       2,359,808\n",
            "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-158            [-1, 512, 8, 8]               0\n",
            "          Conv2d-159           [-1, 2048, 8, 8]       1,050,624\n",
            "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-161           [-1, 2048, 8, 8]               0\n",
            "           block-162           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-163            [-1, 512, 8, 8]       1,049,088\n",
            "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-165            [-1, 512, 8, 8]               0\n",
            "          Conv2d-166            [-1, 512, 8, 8]       2,359,808\n",
            "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-168            [-1, 512, 8, 8]               0\n",
            "          Conv2d-169           [-1, 2048, 8, 8]       1,050,624\n",
            "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-171           [-1, 2048, 8, 8]               0\n",
            "           block-172           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 101]         206,949\n",
            "================================================================\n",
            "Total params: 23,741,541\n",
            "Trainable params: 23,741,541\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 309.45\n",
            "Params size (MB): 90.57\n",
            "Estimated Total Size (MB): 400.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "layers = [3,4,6,3]\n",
        "\n",
        "model = ResNet(block, layers, 3, 101)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "summary(model, (3, 227, 227))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-bGRGx8nOQb",
        "outputId": "597564f6-7906-4214-8595-4712fb47e4fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 0.0585\n",
            "Epoch: 0, Batch: 100, Loss: 0.0257\n",
            "Epoch 0: Loss=0.0275, Accuracy=63.82%\n",
            "Epoch: 1, Batch: 0, Loss: 0.0017\n",
            "Epoch: 1, Batch: 100, Loss: 0.0108\n",
            "Epoch 1: Loss=0.0155, Accuracy=64.23%\n",
            "Epoch: 2, Batch: 0, Loss: 0.0018\n",
            "Epoch: 2, Batch: 100, Loss: 0.0054\n",
            "Epoch 2: Loss=0.0225, Accuracy=64.69%\n",
            "Epoch: 3, Batch: 0, Loss: 0.0045\n",
            "Epoch: 3, Batch: 100, Loss: 0.0971\n",
            "Epoch 3: Loss=0.0089, Accuracy=65.09%\n",
            "Epoch: 4, Batch: 0, Loss: 0.0011\n",
            "Epoch: 4, Batch: 100, Loss: 0.0010\n",
            "Epoch 4: Loss=0.0024, Accuracy=65.73%\n",
            "Epoch: 5, Batch: 0, Loss: 0.0005\n",
            "Epoch: 5, Batch: 100, Loss: 0.0010\n",
            "Epoch 5: Loss=0.0052, Accuracy=65.38%\n",
            "Epoch: 6, Batch: 0, Loss: 0.0007\n",
            "Epoch: 6, Batch: 100, Loss: 0.0018\n",
            "Epoch 6: Loss=0.0061, Accuracy=64.86%\n",
            "Epoch: 7, Batch: 0, Loss: 0.0009\n",
            "Epoch: 7, Batch: 100, Loss: 0.2369\n",
            "Epoch 7: Loss=0.1945, Accuracy=52.02%\n",
            "Epoch: 8, Batch: 0, Loss: 0.5096\n",
            "Epoch: 8, Batch: 100, Loss: 0.2966\n",
            "Epoch 8: Loss=0.4463, Accuracy=58.41%\n",
            "Epoch: 9, Batch: 0, Loss: 0.1962\n",
            "Epoch: 9, Batch: 100, Loss: 0.1001\n",
            "Epoch 9: Loss=0.1349, Accuracy=63.13%\n",
            "Epoch: 10, Batch: 0, Loss: 0.0622\n",
            "Epoch: 10, Batch: 100, Loss: 0.1438\n",
            "Epoch 10: Loss=0.0476, Accuracy=64.46%\n",
            "Epoch: 11, Batch: 0, Loss: 0.0212\n",
            "Epoch: 11, Batch: 100, Loss: 0.0976\n",
            "Epoch 11: Loss=0.0277, Accuracy=64.92%\n",
            "Epoch: 12, Batch: 0, Loss: 0.0039\n",
            "Epoch: 12, Batch: 100, Loss: 0.0032\n",
            "Epoch 12: Loss=0.0189, Accuracy=64.06%\n",
            "Epoch: 13, Batch: 0, Loss: 0.0081\n",
            "Epoch: 13, Batch: 100, Loss: 0.0071\n",
            "Epoch 13: Loss=0.0246, Accuracy=65.55%\n",
            "Epoch: 14, Batch: 0, Loss: 0.0053\n",
            "Epoch: 14, Batch: 100, Loss: 0.0140\n",
            "Epoch 14: Loss=0.0431, Accuracy=61.06%\n",
            "Epoch: 15, Batch: 0, Loss: 0.0873\n",
            "Epoch: 15, Batch: 100, Loss: 0.0218\n",
            "Epoch 15: Loss=0.0482, Accuracy=61.41%\n",
            "Epoch: 16, Batch: 0, Loss: 0.0062\n",
            "Epoch: 16, Batch: 100, Loss: 0.0463\n",
            "Epoch 16: Loss=0.0493, Accuracy=61.18%\n",
            "Epoch: 17, Batch: 0, Loss: 0.0793\n",
            "Epoch: 17, Batch: 100, Loss: 0.1056\n",
            "Epoch 17: Loss=0.1322, Accuracy=60.31%\n",
            "Epoch: 18, Batch: 0, Loss: 0.2124\n",
            "Epoch: 18, Batch: 100, Loss: 0.1743\n",
            "Epoch 18: Loss=0.1355, Accuracy=60.08%\n",
            "Epoch: 19, Batch: 0, Loss: 0.0632\n",
            "Epoch: 19, Batch: 100, Loss: 0.0201\n",
            "Epoch 19: Loss=0.1018, Accuracy=62.67%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "        # Print progress\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Epoch {epoch}: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%')\n",
        "\n",
        "    # Save best model\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        torch.save(model.state_dict(), 'best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "M1v-20d-fjrq",
        "outputId": "7d04c5aa-5dc1-43be-d593-cf61eae2ef37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 4.8311\n",
            "Epoch: 0, Batch: 100, Loss: 3.8643\n",
            "Loss after 1 epochs: 5.121669146808865\n",
            "Epoch: 1, Batch: 0, Loss: 4.2141\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b69b2a271ee9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_hat = model(images)\n",
        "    loss = criterion(y_hat, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item() * labels.size(0)\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "  avg_loss = total_loss/len(train_loader.dataset)\n",
        "  print(f\"Loss after {epoch+1} epochs: {avg_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W8TET_kf9lP"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    images = (images - images.mean())/images.std()\n",
        "    y_hat = model(images)\n",
        "    _, y_hat = torch.max(y_hat, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (y_hat == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f'Epoch {epoch}: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%')\n",
        "\n",
        "  # Save best model\n",
        "  if accuracy > best_acc:\n",
        "      best_acc = accuracy\n",
        "      torch.save(model.state_dict(), 'best_model.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMquwbjq4NIdh9Qr/y1oFYk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}